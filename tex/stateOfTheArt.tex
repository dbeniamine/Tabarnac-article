%!TEX encoding=UTF-8 Unicode
%!TEX root=../tabarnac.tex

\section{Related Work}
\label{sec:soa}

This section presents an overview of related work in the area of data mapping mechanisms and memory access profiling of parallel applications based on shared memory.

\subsection{Data Mapping Mechanisms}
\label{sec:soa-mapping}

From a high-level view, data mapping mechanisms can be classified into two categories.
Mechanisms that have information about the memory accesses before the application starts executing, and mechanisms without prior information that need to determine the memory access behavior during execution of the parallel application.
Mechanisms that have prior information can have higher improvements compared to mechanisms without prior information, as the collection of information during runtime has a potentially high overhead, limiting the amount and accuracy of information that can be collected.
Furthermore, opportunities for improvements are lost while information about the memory access pattern is collected.
On the other hand, if the memory access behavior is analyzed during application execution, no prior analysis is required.
Figure~\ref{fig:timeline} shows a comparison of the operation of these two types of applications with a parallel application consisting of four threads.
In this example, a mechanism with prior information can perform the mapping as soon as the parallel phase starts (or even earlier), while mechanisms without this information need to learn the behavior for some time and can perform mapping decisions only at a later stage of the execution.

\begin{figure}[!b]
    % \includegraphics[width=\linewidth]{img/timeline}
    \input{img/timeline}
    \caption{Comparison of data mapping mechanisms with and without prior information about the memory access behavior of a parallel application consisting of four threads. Training is similar to the normal execution, but with additional training overhead.}
    \label{fig:timeline}
\end{figure}

\subsubsection{Mechanisms Without Prior Information}

% kernel old
Most mechanisms that have no prior information about the memory access behavior operate within the operating system.
Traditionally, operating systems have used the \emph{first-touch}~\cite{Marchetti1995}, \emph{next-touch}~\cite{Lof2005} and \emph{interleave}~\cite{Kleen2004} policies to map memory pages to NUMA nodes.
The first-touch policy~\cite{Marchetti1995}, which is the default policy in most current operating systems (such as Linux), allocates a page on the NUMA node that performs the first memory access to it.
The page is never migrated between nodes.
First-touch requires that the programmer takes care of which thread accesses data first.
In some circumstances, this policy can lead to reduced performance, for
instance when a single thread initializes a large part of the memory and places most pages on a single node.
In next-touch~\cite{Lof2005}, each page is periodically migrated to the NUMA node that performs the next access to a page.
This policy can lead to excessive page migrations if the memory access behavior is changing fast.
The interleave policy (which is available in Linux via the \texttt{numactl} tool~\cite{Kleen2004} for example) distributes memory pages equally among all NUMA nodes, but does not take any locality of memory accesses into account.

Newer developments in operating systems focus on refining the data mapping during the execution of parallel applications, using online profiling of memory accesses to guide migration decisions.
Recent versions of the Linux kernel (starting with version 3.8) contain the NUMA Balancing technique~\cite{Corbet}, which uses page faults during execution to determine if a page should be migrated to a different NUMA node. To increase the accuracy of this mechanism, extra page faults are inserted during execution, creating an additional overhead.
A similar proposal is the AutoNUMA approach~\cite{Corbet2012}.
Neither mechanism maintains an access history. This eliminates the need to store the access behavior, but also makes them susceptible to excessive migrations.
Other proposals store such an access history.
Dashti et al.~\cite{Dashti2013} introduced the Carrefour mechanism, which uses instruction-based sampling~(IBS)~\cite{Drongowski07Instructionbased} available in recent AMD architectures~\cite{AMD2012} to detect the memory access behavior.
kMAF~\cite{Diener2014} is a similar mechanism that uses page faults to analyze the behavior.
Due to the access history, these mechanisms can avoid excessive migrations, but still suffer from later migrations and a runtime overhead compared to mechanisms with prior information.

% hardware
% marathe, lapt

\subsubsection{Mechanisms With Prior Information}

Most mechanisms with prior information about memory access behavior perform mapping in user space, on the compiler or runtime library level.
Piccoli et al.~\cite{Piccoli2014} propose a compiler extension that analyzes the memory access pattern of loops that are executed in parallel and use this information to migrate pages before the loop is entered.
Nikolopoulos et al.~\cite{Nikolopoulos2000a,Nikolopoulos2000} present an integrated compiler/OS-based data mapping mechanism based on a custom OpenMP compiler and IRIX kernel extensions. The compiler inserts instrumentation code to identify access patterns to shared memory areas and to guide migration decisions.
ForestGOMP~\cite{Broquedis2010a} requires source code annotations to identify memory access behavior and is limited to the OpenMP library.
These techniques use predictions about the memory access behavior, which might be dependent on input data and can cause wrong mappings.
Furthermore, no improvements to the memory access pattern are performed.

Libraries that support NUMA-aware memory allocation include libnuma~\cite{Kleen2004} and MAi~\cite{Ribeiro2009}. With these libraries, data structures can be allocated according to the specification of the programmer, such as on a particular NUMA node, or with an interleave policy. These techniques can achieve large improvements, but place the burden of the mapping on the programmer, who has to determine the best placement himself.
% An evolution of MAi, the Minas framework~\cite{Ribeiro2010}, optionally uses a source code preprocessor to determine data mapping policies for arrays.
%
Previous research also uses memory access traces to perform data mapping~\cite{Diener2015,Marathe2010,Bolosky1992}. These can be useful to determine the maximum gains that can be achieved with mapping policies, but are not applicable in general due to their substantial overhead and the fact that the access behavior might change with different input data and different numbers of threads, for instance.
Generic tools to evaluate parallel application performance, such as Intel's VTune~\cite{Reinders05VTune} and Performance Counter Monitor~(PCM)~\cite{Intel2012b}, the HPCToolkit~\cite{Adhianto10HPCTOOLKIT}, and AMD's CodeAnalyst~\cite{Drongowski2008}, provide only indirect information about the memory access behavior and do not propose specific strategies to improve it.


\subsection{Memory Access Profiling}
\label{sec:soa-profiling}

Many tools were designed to analyze and improve NUMA behavior. Nevertheless, analyzing
memory accesses is a challenge due to the large amount of information to store and process.
Several tools~\cite{Lachaize12MemProf,McCurdy2010} address this difficulty by
using sampling mechanisms such as AMD's Instruction Based
Sampling (IBS). Not only can sampling miss important events, leading to inaccurate characterizations, but \emph{IBS} is a non-portable \emph{AMD}
technology, therefore such tools can only be used in special circumstances. Another approach is to
use hardware performance counters~\cite{Majo13(Mis)understanding,
Jiang14Understanding,Bosch00Rivet,Weyers14Visualization,Tao01Visualizing},
which are special hardware registers that record events such as cache
misses and remote memory accesses, among others. These counters only provide a partial view
of the execution, they show events happening on the processor related to
memory, but not what triggered these events.

The second difficulty of memory analysis is to present the information in such a
way that the user can use it to improve the application. Some of the tools previously mentioned only provide
a textual output~\cite{Lachaize12MemProf,McCurdy2010}. Even if these tools highlight the most relevant informations, it is hard to get an overview of the memory behavior from such output. The user might be faced with a
huge amount of information and not be able to differentiate normal behaviors from
problematic ones. Other tools provide more advanced visualizations. For
instance, Tao et al.~\cite{Tao01Visualizing} propose a detailed view of each memory
page, showing the number of remote and local accesses from each NUMA node. Weyers et
al.~\cite{Weyers14Visualization} depict the memory bandwidth between each pair of nodes,
showing where the remote accesses occur. Finally, Bosch et al.~\cite{Bosch00Rivet} give several views of the execution and the possibility to
navigate through them.

Although all these tools can help developers and users to understand the kind of performance issues they are facing, they never give the
reason \emph{why} a certain behavior is happening, which code caused it, or how to improve it.
Previous studies aimed to answer this question for some specific
benchmarks~\cite{Majo13(Mis)understanding,Jiang14Understanding}.
However, these studies use manual source code analysis and performance counters and do not provide a general tool or methodology that is usable for other applications.

\subsection{Summary of Related Work}

Summarizing our discussion of previous work in this area, we conclude that tools to improve the memory access behavior on NUMA architectures with prior information have the highest potential for improvements.
The two main challenges for this type of tool is to gather information about the memory access patterns in a fast, accurate and easy-to-use way, and providing information to the developers about the ways to improve the behavior of their applications.
Our proposed tool, \TABARNAC, provides a comprehensive solution for these challenges.

% \MD{mechanisms with prior information have highest potential for improvements, but currently:
% - lack of information about memory access behavior
% - lack of information about ways to improve behavior
% }
% Importance of Mapping:
% \begin{itemize}
%     \item First touch
%     \item Interleave
% \end{itemize}

% Why Not automated tools
% \begin{itemize}
%     \item Trainning time
%     \item Garbage in/ garbage out (matrix modulo / bloc)
% \end{itemize}

% New tool: understand why performances are bad
