%!TEX encoding=UTF-8 Unicode
%!TEX root=../tabarnac.tex

\section{TABARNAC}
\label{sec:design}

\TABARNAC is divided into two parts: the instrumentation tool and the
visualization. In this section, we discuss the implementation of both parts.

\subsection{Instrumentation}
\label{sec:design-impl}

The instrumentation part of \TABARNAC is based on a custom memory tracer for the Pin dynamic binary instrumentation tool~\cite{Luk05Pin}.
Before running the application, our tool retrieves static memory allocation
information using the \texttt{libelfg0} library. Dynamic allocations are
intercepted with a \texttt{malloc} replacement. If the application is
compiled with debug flags (\texttt{-g}), the structure names that are malloced can be extracted from the source
code. Finally, each time a thread is created, we compute
its stack bounds, and create a virtual structure named \texttt{Stack\#N} where
$N$ is the thread id. Only structures that are bigger than one page (usually
$4$Kib) are recorded as our
analysis granularity is the memory page. The data structure informations (name,
size and address) are not used during the instrumentation, they are only
printed in a file at the end of the analysis to be used by the visualization
tool.

During the execution, every memory access of the parallel application is traced.
For each access, we store the type of access (read or write), the memory page that was accessed, and the thread ID.
The information is stored on a per-thread basis, as shown in
Listing~\ref{lst:mem}, making the code completely lock-free as well as minimizing the amount of false sharing.

%\begin{figure}[!h]
\begin{lstlisting}[caption={Code executed on each memory access. The \texttt{address}, \texttt{threadid} and \texttt{type} parameters are from Pin.},label=lst:mem]
	void mem_access(uint64_t address, uint32_t threadid, char type) {
		uint64_t page = address >> page_bits;
		acc[threadid][page][type]++;
	}

\end{lstlisting}
%\caption{Code that is executed on each memory access.}
%\label{fig:code}
%\end{figure}


After tracing finishes, we generate two \texttt{csv} files.
The first file contains the list of pages and the number of reads
and writes per threads. The second file contains the
list of structures with their names, sizes and start addresses.
We then call an R-markdown script which reads the two \texttt{csv} files,
retrieves the page / data structure mapping and generates the final
visualization presented in the next subsection. We use R-markdown
for the visualization.

% not relevant I'd say:
% \TABARNAC have very few dependencies and can be installed easily. If all the R
% library required to generate the visualization are not present, our tool is
% able to install them automatically. By default \TABARNAC generate the memory
% trace and the visualization, but the user can also choose to only generate the
% memory trace or the visualization. This is useful for people who cannot
% install R on the machine used to generate the trace. Moreover it allows the
% user to customize the plots generate by the R script.

\subsection{Visualization}
\label{sec:design-visu}

Providing an easy to read visualization of a memory trace is a challenge. We
opted for an assisted visualization. Once the analysis phase is done, \TABARNAC
will generates an HTML page, providing a summary of the trace through several
plots.  This HTML page is generated using R markdown as well.  Each plot is
introduced by an explanation of its presentation, what usual issues it can
help to understand and we give hints on how to fix the issues.

The visualization starts with a small introduction, reminding the main
principles while developing for NUMA machines, then it shows the analysis
machine's topology using Hwloc~\cite{Broquedis10hwloc}.

In the next part, the visualization focuses on data structures usage. Some
structures might be ignored for two reason: either no accesses have been
detected during the analysis, which happens for structures used by external
libraries, or less than 0.01\% of the total accesses happens on them. This is
done to make the output more readable. However, it is possible to ask
\TABARNAC not to ignore structures in the second case.

\begin{figure}[htb]
    \centering
    \subfigure[Size of structures in pages.]{
        \includegraphics[width=.45\linewidth]{example_sz}
        \label{fig:example_sz}
    }
    \subfigure[First touch distribution inside one structure.
%   Each point shows which thread is responsible of the first access on one page.
    ]{
        \includegraphics[width=.45\linewidth]{example_ft}
        \label{fig:example_ft}
    }
    \label{fig:example_plot1}
    \caption{Global view of memory behavior.}
\end{figure}

The first series of plots aims at giving information concerning the relative
importance of data structures. It consists of three plots showing first the
size of  each data structures, as in Figure~\ref{fig:example_sz}, then the
number of read and write done from each thread on each structure (Figure~\ref{fig:example_rw}) and
finally the total number of read and write per structures. These plots gives a
general idea of the structures used by threads, it allows also to identify
master/slave patterns.  Moreover, knowing the read/write behavior is very
useful as it determines the possible optimization. For instance, structures
written only at initialization (or very rarely) can be (relatively) easily
duplicated so that each NUMA node works on a local copy.

\begin{figure}[htb]
    \centering
    \subfigure[Number of Read and Write per threads and per structure.]{
        \includegraphics[width=.45\linewidth]{example_rw}
        \label{fig:example_rw}
    }
    \subfigure[Access distribution per thread inside one structure.
%    Each point represents the number of access to one page done by one thread.
    ]{
        \includegraphics[width=.45\linewidth]{example_dist}
        \label{fig:example_dist}
    }
    \caption{Per thread view of memory behavior.}
    \label{fig:example_plot2}
\end{figure}

The second series of plots is the most important one, it shows for each thread
and each structure the distribution of accesses inside the structure. As we
can see in Figure~\ref{fig:example_dist}, each point represent the number of
accesses done by one thread to one page. It gives an easy way to understand data
sharing between threads and structures usage. They can be used to identify
inefficient memory usage or to determine the best NUMA mapping policy.

%\begin{figure}[htb]
%    \centering
%    \includegraphics[height=.2\textheight]{example_ft}
%    \caption{Example of first touch distribution Each point show which thread
%    is responsible of the first access on one page.}
%    \label{fig:example_ft}
%\end{figure}


Finally, \TABARNAC provides a plot that shows for each page of each structure
which thread was responsible for the first touch
(Figure~\ref{fig:example_ft}). This information is quite relevant as the
default policy for Linux is to map a page as close as possible to the first
thread accessing it. If the first touch distribution doest not fit the actual
access distribution, the default mapping done by \emph{Linux} might not be
efficient.  To improve this issue, the developer can either solve the first
touch or do some manual data mapping to ensure better memory access locality
during the execution.
